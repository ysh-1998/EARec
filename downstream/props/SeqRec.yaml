n_layers: 2
n_heads: 2
hidden_size: 300
inner_size: 256
hidden_dropout_prob: 0.5
attn_dropout_prob: 0.5
hidden_act: 'gelu'
layer_norm_eps: 1e-12
initializer_range: 0.02
loss_type: 'CE'

item_drop_ratio: 0.2
item_drop_coefficient: 0.9
lambda: 1e-3

plm_suffix: featEARec.tvb
plm_size: 4096
adaptor_layers: [4096,300]
